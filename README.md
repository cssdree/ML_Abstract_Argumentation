# Machine Learning for Abstract Argumentation
This project aims to develop neural models capable of determining the acceptability of arguments within Incomplete Argumentation Frameworks (IAFs). The models are first trained and tested on a dataset generated as part of this project, and then evaluated on the benchmarks provided by ICCMA 2023.

## Installation
1. Install the **Taeydennae** solver from this repository : [https://bitbucket.org/andreasniskanen/taeydennae/src/master/](https://bitbucket.org/andreasniskanen/taeydennae/src/master/)
2. Install the **af_reader_py** module from this repository : [https://github.com/Paulo-21/AF-GCN-GAT_wGS](https://github.com/Paulo-21/AF-GCN-GAT_wGS)
3. Install the dependencies according to your hardware configuration :
```bash
pip install -r requirements-cpu.txt
```
```bash
pip install -r requirements-cuda.txt
```
4. Download and transform the ICCMA 2023 AFs into IAFs :
```bash
python3 Benchmarks/build_ICCMA2023_dataset.py
```

## Configuration
Before running any script, ensure the desired settings are uncommented in the `CONFIG.py` file. Three variables can be configured :
#### IAF_root variable
This variable specifies which dataset to access.
- `Data/IAF_TrainSet` for the training set of the small dataset
- `Data/IAF_TestSet` for the test set of the small dataset
- `Benchmarks/ICCMA2023-inc` for the ICCMA 2023 dataset
#### Sem variable
This variable specifies the semantics to use. You can choose among the following three options : ST for stable semantics, PR for preferred semantics or GR for grounded semantics.
#### Completion variable
This variable defines how the model handles completions during the training and prediction phases.
- `MINMAX` to use both minimum and maximum completions
- `MIN` to use only the minimum completion
- `MAX` to use only the maximum completion

## Usage

### I - Data : Small dataset
To generate and label the small dataset (run this twice, once for the train set and once for the test set, updating `IAF_root` in `CONFIG.py` each time) :
```bash
python3 -m Data.Generation
python3 -m Data.Labeling
```

### II - GNN : Graph neural networks
To train a neural model on the previously generated small dataset:
```bash
python3 -m GNN.Training
```
To predict the acceptability of an argument from the small dataset with a previously trained model :
```bash
python3 -m GNN.iaf_egat_predict filepath problem-sem-com argument
```
- **filepath** : path to the `.apx` file (including the `.apx` extension)
- **problem** : decision problem (PCA, NCA, PSA, or NSA)
- **sem** : semantics (ST, PR, or GR)
- **completion** : completion mode (MINMAX, MIN or MAX)
- **argument** : index of the argument to evaluate

To test the speed and performance of a model on the small dataset:
```bash
python3 -m GNN.Test
```

### III - BigData : ICCMA 2023 dataset
To predict the acceptability of an argument from the ICCMA 2023 dataset with a previously trained model :
```bash
python3 -m BigData.big_iaf_egat_predict filepath problem-sem-completion argument
```
To test the speed and performance of a model on the ICCMA 2023 dataset:
```bash
python3 -m BigData.Test
```

## Filenames
The .apx files generated by the `Generation.py` script all follow the same naming structure (`BA_10_1_0.1_arg-inc_120` or `ER_20_0.3_0.2_inc_20` for example). The filename components are as follows :
- Method : ER for Erdos-RÃ©nyi, WS for Watts-Strogatz or BA for Barabasi-Albert
- Number of arguments
- Parameter : either a probability or a number of attacks
- Probability used to determine argument or attack uncertainty
- "inc" when both uncertain arguments and attacks, "arg-inc" when only uncertain arguments and "att-inc" when only uncertain attacks
- Unique graph identifier

## Models
Nine pre-trained models are available, covering all combinations of the 3 semantics (ST, PR, GR) and the 3 completion modes (MINMAX, MIN, MAX). Model weights are located in the `GNN/models` folder.